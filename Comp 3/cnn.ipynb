{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('data/train_and_test.npz') as data:\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    X_train = data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[20000])\n",
    "plt.title(y_train[20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different tries at various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(y_train)\n",
    "img_size = 32\n",
    "n_filters = 3\n",
    "n_dense = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               kernel_size=(3,3), # filter size\n",
    "               strides=(1,1),\n",
    "               padding='same',\n",
    "               input_shape=(32, 32, 3),\n",
    "               activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "\n",
    "cnn.add(Dropout(0.4))\n",
    "\n",
    "cnn.add(Conv2D(filters=64,\n",
    "               kernel_size=(2,2),\n",
    "               strides=(1,1),\n",
    "               padding='valid'))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(64))\n",
    "cnn.add(Activation('relu'))\n",
    "\n",
    "cnn.add(Dropout(0.4))\n",
    "\n",
    "cnn.add(Dense(1))\n",
    "cnn.add(Activation('sigmoid'))\n",
    "\n",
    "cnn.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               kernel_size=(3,3), # filter size\n",
    "               strides=(1,1),\n",
    "               padding='same',\n",
    "               input_shape=(32, 32, 3),\n",
    "               activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units=128, activation='relu')) # hidden layer. TODO: optimize units value\n",
    "cnn.add(Dense(units=1, activation='sigmoid'))\n",
    "# adam=ADAM\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy = 0.046 vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.dlology.com/blog/one-simple-trick-to-train-keras-model-faster-with-batch-normalization/\n",
    "# https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "\n",
    "# bad model\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, (3,3), use_bias=False))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Activation('relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "\n",
    "cnn.add(Conv2D(32, (3,3), use_bias=False))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Activation('relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2),\n",
    "                     strides=2))\n",
    "\n",
    "cnn.add(Conv2D(32, (3,3), use_bias=False))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Activation('relu'))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually working model??? !! vv\n",
    "#### Accuracy caps off at 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 32)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 43)                2795      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 94,347\n",
      "Trainable params: 93,899\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiffany/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(2, 2), activation=\"relu\", padding=\"same\")`\n",
      "/home/tiffany/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(2, 2), activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/kentaroyoshioka47/cnn-with-batchnormalization-in-keras-94\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "filter_pixel = 2\n",
    "noise = 1\n",
    "droprate = 0.25\n",
    "\n",
    "model = Sequential()\n",
    "#convolution 1st layer\n",
    "model.add(Conv2D(32, kernel_size=(filter_pixel, filter_pixel), padding=\"same\",\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape)) #0\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                       strides=2))\n",
    "model.add(Dropout(droprate))#3\n",
    "\n",
    "#convolution 2nd layer\n",
    "model.add(Conv2D(64, kernel_size=(filter_pixel, filter_pixel), activation='relu',border_mode=\"same\"))#1\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(droprate))#3\n",
    "\n",
    "#convolution 3rd layer\n",
    "model.add(Conv2D(64, kernel_size=(filter_pixel, filter_pixel), activation='relu',border_mode=\"same\"))#1\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(droprate))#3\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Flatten()) #7\n",
    "model.add(Dense(64,use_bias=False)) #13\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu')) #14\n",
    "model.add(Dropout(droprate))      #15\n",
    "\n",
    "#Fully connected final layer\n",
    "model.add(Dense(43)) #8\n",
    "model.add(Activation('softmax')) #9\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "39209/39209 [==============================] - 37s 954us/step - loss: 1.7698 - accuracy: 0.5001\n",
      "Epoch 2/25\n",
      "39209/39209 [==============================] - 43s 1ms/step - loss: 0.5929 - accuracy: 0.8178\n",
      "Epoch 3/25\n",
      "39209/39209 [==============================] - 43s 1ms/step - loss: 0.3633 - accuracy: 0.8875\n",
      "Epoch 4/25\n",
      "39209/39209 [==============================] - 42s 1ms/step - loss: 0.2769 - accuracy: 0.9129\n",
      "Epoch 5/25\n",
      "39209/39209 [==============================] - 42s 1ms/step - loss: 0.2336 - accuracy: 0.9256\n",
      "Epoch 6/25\n",
      "39209/39209 [==============================] - 44s 1ms/step - loss: 0.2045 - accuracy: 0.9338\n",
      "Epoch 7/25\n",
      "39209/39209 [==============================] - 41s 1ms/step - loss: 0.1847 - accuracy: 0.9404\n",
      "Epoch 8/25\n",
      "39209/39209 [==============================] - 38s 979us/step - loss: 0.1718 - accuracy: 0.9441\n",
      "Epoch 9/25\n",
      "39209/39209 [==============================] - 39s 988us/step - loss: 0.1538 - accuracy: 0.9502\n",
      "Epoch 10/25\n",
      "39209/39209 [==============================] - 39s 1ms/step - loss: 0.1484 - accuracy: 0.9507\n",
      "Epoch 11/25\n",
      "39209/39209 [==============================] - 41s 1ms/step - loss: 0.1428 - accuracy: 0.9534\n",
      "Epoch 12/25\n",
      "39209/39209 [==============================] - 40s 1ms/step - loss: 0.1351 - accuracy: 0.9551\n",
      "Epoch 13/25\n",
      "39209/39209 [==============================] - 42s 1ms/step - loss: 0.1354 - accuracy: 0.9561\n",
      "Epoch 14/25\n",
      "39209/39209 [==============================] - 43s 1ms/step - loss: 0.1197 - accuracy: 0.9616\n",
      "Epoch 15/25\n",
      "39209/39209 [==============================] - 42s 1ms/step - loss: 0.1176 - accuracy: 0.9617\n",
      "Epoch 16/25\n",
      "39209/39209 [==============================] - 44s 1ms/step - loss: 0.1155 - accuracy: 0.9620\n",
      "Epoch 17/25\n",
      "39209/39209 [==============================] - 40s 1ms/step - loss: 0.1071 - accuracy: 0.9647\n",
      "Epoch 18/25\n",
      "39209/39209 [==============================] - 39s 1ms/step - loss: 0.1085 - accuracy: 0.9635\n",
      "Epoch 19/25\n",
      "39209/39209 [==============================] - 40s 1ms/step - loss: 0.1065 - accuracy: 0.9648\n",
      "Epoch 20/25\n",
      "39209/39209 [==============================] - 40s 1ms/step - loss: 0.1011 - accuracy: 0.9676\n",
      "Epoch 21/25\n",
      "39209/39209 [==============================] - 43s 1ms/step - loss: 0.1039 - accuracy: 0.9662\n",
      "Epoch 22/25\n",
      "39209/39209 [==============================] - 42s 1ms/step - loss: 0.0954 - accuracy: 0.9687\n",
      "Epoch 23/25\n",
      "39209/39209 [==============================] - 44s 1ms/step - loss: 0.0946 - accuracy: 0.9696\n",
      "Epoch 24/25\n",
      "39209/39209 [==============================] - 44s 1ms/step - loss: 0.0942 - accuracy: 0.9687\n",
      "Epoch 25/25\n",
      "27488/39209 [====================>.........] - ETA: 12s - loss: 0.0902 - accuracy: 0.9704"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "y_binary = to_categorical(y_train)\n",
    "hist = model.fit(X_train, \n",
    "               y_binary, \n",
    "               epochs=EPOCHS,\n",
    "               batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
