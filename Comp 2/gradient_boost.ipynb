{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, x, y):\n",
    "    print('Score:        {:.4f}%'.format(model.score(x, y) * 100))\n",
    "    print('Kaggle Score: {:.0f}'.format(np.sqrt(np.mean((model.predict(x) - y)**2))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG Data Size:(12379, 226)\n",
      "New Data Size:(8977, 156)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Data\n",
    "\n",
    "df = pd.read_csv('data/stock_XY_train.csv')\n",
    "print('OG Data Size:{}'.format(df.shape))\n",
    "\n",
    "\n",
    "dropped_columns = (df[df.columns[df.isnull().mean() > 0.15]].columns)\n",
    "df = df[df.columns[df.isnull().mean() < 0.15]] # TO-DO: Tinker around with mean threshold.\n",
    "df = df.dropna()\n",
    "print('New Data Size:{}'.format(df.shape))\n",
    "del df['operatingProfitMargin'] # Got rid of this column because it is all `1`. No reason to keep.\n",
    "\n",
    "del df['Ticker']\n",
    "del df['Sector']\n",
    "del df['Yr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating to train and test data\n",
    "train_df = df.sample(frac=0.8,random_state=0)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Grabbing stats in order to normalize data\n",
    "train_stats = train_df.describe()\n",
    "train_stats.pop('Buy')\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "# Separating labels\n",
    "train_label = train_df.pop('Buy')\n",
    "test_label = test_df.pop('Buy')\n",
    "\n",
    "# Normalizing Data\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm(train_df)\n",
    "normed_test_data = norm(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5, 8],\n",
    "    'learning_rate': [0.05, 0.075,],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "}\n",
    "\n",
    "gradient_boosting_regressor = GridSearchCV(\n",
    "    ensemble.GradientBoostingRegressor(),\n",
    "    params,\n",
    ")\n",
    "\n",
    "\n",
    "gradient_boosting_regressor.fit(normed_train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40920939634251746\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(gradient_boosting_regressor.score(normed_train_data, train_label))\n",
    "print(gradient_boosting_regressor.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=5,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.loc[:, df.columns != 'Buy'].columns\n",
    "columns\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(normed_train_data[columns], df['Buy'], test_size=0.4, random_state=42)\n",
    "\n",
    "gb = ensemble.GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.05, criterion='mse')\n",
    "gb.fit(normed_train_data, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:        20.5369%\n",
      "Kaggle Score: 0\n"
     ]
    }
   ],
   "source": [
    "print_score(gradient_boosting_regressor, normed_test_data, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
